import time
import numpy as np
import os
import warnings
from PIL import Image
import torch
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms

import argparse

warnings.filterwarnings("ignore")

### Dataset ###
class MiniImageNetDataset(Dataset):
    def __init__(self, root_dir, split='train', transform=None):
        self.root_dir = root_dir
        self.split = split
        self.transform = transform

        self.image_paths = []
        self.labels = []

        split_path = os.path.join(root_dir, f'{split}.csv')
        with open(split_path, 'r') as f:
            next(f)
            for line in f:
                img_name, label = line.strip().split(',')
                self.image_paths.append(os.path.join(root_dir, 'images', img_name))
                self.labels.append(label)
        self.label2idx = {label: idx for idx, label in enumerate(sorted(set(self.labels)))}

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image = Image.open(self.image_paths[idx]).convert('RGB')
        label = self.labels[idx]
        label = self.label2idx[label]

        if self.transform:
            image = self.transform(image)

        return image, label


### DataLoader measure time ###
def measure_time(dataloader, device):
    runtime_list = []
    for i, t in dataloader:
        stime = time.perf_counter_ns()
        i, t = i.to(device), t.to(device)
        if device.type == 'cuda':
            torch.cuda.synchronize()  # Wait for GPU tasks to finish
        etime = time.perf_counter_ns()
        runtime_list.append((etime - stime) * 1e-6)  # Convert ns to ms

    if len(runtime_list) == 0:
        return float('inf'), 0  # Default for no data
    avg_runtime = np.mean(runtime_list)
    std_runtime = np.std(runtime_list)
    return avg_runtime, std_runtime

### My algorithm ###
def binary_search_with_base(dataset, batch_size, base_runtime, num_workers_list, device, direction, default_num_workers):
    runtime = base_runtime
    best_runtime = float('inf')
    best_config = None
    
    # Find the index of default_num_workers
    if default_num_workers not in num_workers_list:
        raise ValueError(f"default_num_workers {default_num_workers} not in num_workers_list.")
    
    # Position of default_num_workers
    default_index = num_workers_list.index(default_num_workers)

    if direction == "lower":
        left, right = 0, default_index  # Left range based on default_num_workers
    else:
        left, right = default_index, len(num_workers_list) - 1  # Right range based on default_num_workers

    while left <= right:
        mid = (left + right) // 2
        num_workers = num_workers_list[mid]  # Setting the num_workers to middle value 

        # Grid_search  ( fixed num_workers )
        runtime, config = grid_search(dataset, batch_size, num_workers, device)

        if runtime < best_runtime:
            best_runtime = runtime
            best_config = config
            # Narrow to the range
            if direction == "lower":
                right = mid - 1  # "lower"  Narrow to the left based on the middle value in the range
            else:
                left = mid + 1  # "upper" Narrow to the right based on the middle value in the range
        else:
            # Narrow to direction if performance is bad
            if direction == "lower":
                left = mid + 1
            else:
                right = mid - 1

    return best_runtime, best_config


def your_algorithm(dataset, batch_size):

    num_workers_list = [0, int(cpu_core*(1/16)), int(cpu_core*(1/8)), int(cpu_core*(1/4)), int(cpu_core*(1/2)), cpu_core,
                            int(cpu_core*(2)),int(cpu_core*(4)),int(cpu_core*(8)),int(cpu_core*(16))]  # set up the num_workers_list
    
    default_num_workers = int(os.cpu_count()/2) 

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # base_runtime searching : grid_search run with default num_workers
    base_runtime, _ = grid_search(dataset, batch_size, num_workers=default_num_workers, device=device)

    # Lower range search (in the num_workers_list)
    lower_runtime, lower_config = binary_search_with_base(
        dataset, batch_size, base_runtime, num_workers_list, device, "lower", default_num_workers
    )

    # Upper range search (in the num_workers_list)
    upper_runtime, upper_config = binary_search_with_base(
        dataset, batch_size, base_runtime, num_workers_list, device, "upper", default_num_workers
    )

    # Return to the optimal value
    if lower_runtime < upper_runtime:
        return lower_config
    else:
        return upper_config



def grid_search(dataset, batch_size, num_workers, device):
    
    prefetch_factor_list = [
        int(cpu_core * (1/16)),
        int(cpu_core * (1/8)),
        int(cpu_core * (1/4)),
        int(cpu_core * (1/2)),
        cpu_core,
        int(cpu_core * 2)
    ]
    persistent_workers_list = [False, True]
    pin_memory_list = [False, True]


    best_runtime = float('inf')
    best_config = None

    for prefetch_factor in ([None] if num_workers == 0 else prefetch_factor_list):
        if prefetch_factor is not None and prefetch_factor <= 0:
            continue  # Skip invalid prefetch_factor values
        for persistent_workers in ([False] if num_workers == 0 else persistent_workers_list):
            for pin_memory in pin_memory_list:
                if num_workers == 0 and persistent_workers:
                    continue

                dataloader = DataLoader(
                    dataset=dataset,
                    batch_size=batch_size,
                    num_workers=num_workers,
                    prefetch_factor=prefetch_factor,
                    persistent_workers=persistent_workers,
                    pin_memory=pin_memory,
                )

                avg_runtime, _ = measure_time(dataloader, device)
                
                # Update the best configuration
                if avg_runtime < best_runtime:
                    best_runtime = avg_runtime
                    best_config = {
                        'num_workers': num_workers,
                        'prefetch_factor': prefetch_factor,
                        'persistent_workers': persistent_workers,
                        'pin_memory': pin_memory,
                    }
                
                    
    return best_runtime, best_config




if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--batch_size",type=int, default =2, help = "Batch size for DataLoader") # 32, ,64 ,128 ,256 
    args = parser.parse_args()
    batch_size = args.batch_size
    dataset = MiniImageNetDataset(
        root_dir='/home/myhoon/work/dataloader/dataloader',
        split='train',
        transform=transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.RandomCrop((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            ),
        ])
    )

    a_start_time = time.time()
    best_config = your_algorithm(dataset, batch_size)
    a_end_time = time.time()

    dataloader = DataLoader(dataset=dataset, batch_size=batch_size, **best_config)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    avg_runtime, std_runtime = measure_time(dataloader, device)

    print("\n--- Final Results ---")
    print(f"Best Configuration: {best_config}")
    print(f"Average Runtime: {avg_runtime:.4f} ms")
    print(f"Standard Deviation: {std_runtime:.4f} ms")
    print(f"Parameter Search Time: {a_end_time - a_start_time:.4f} seconds")
