import os
import time
import warnings
import numpy as np
from PIL import Image

import torch
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms

warnings.filterwarnings("ignore")


### Dataset ###
class MiniImageNetDataset(Dataset):
    def __init__(self, root_dir, split='train', transform=None):
        self.root_dir = root_dir
        self.split = split
        self.transform = transform

        self.image_paths = []
        self.labels = []

        split_path = os.path.join(root_dir, f'{split}.csv')
        with open(split_path, 'r') as f:
            next(f)
            for line in f:
                img_name, label = line.strip().split(',')
                self.image_paths.append(os.path.join(root_dir, 'images', img_name))
                self.labels.append(label)

        self.label2idx = {label: idx for idx, label in enumerate(sorted(set(self.labels)))}

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image = Image.open(self.image_paths[idx]).convert('RGB')
        label = self.label2idx[self.labels[idx]]
        if self.transform:
            image = self.transform(image)
        return image, label


### DataLoader measure time ###
def measure_time(dataloader, device):
    """
    Measure the average runtime and standard deviation for data loading.

    Args:
        dataloader (DataLoader): DataLoader to measure.
        device (torch.device): Device to load data onto.

    Returns:
        tuple: (Average runtime in ms, Standard deviation in ms)
    """
    runtime_list = []
    for i, t in dataloader:
        stime = time.perf_counter_ns()
        i, t = i.to(device), t.to(device)
        torch.cuda.synchronize()  # Wait for all GPU tasks to finish
        etime = time.perf_counter_ns()
        runtime_list.append((etime - stime) * 1e-6)  # Convert ns to ms

    avg_runtime = np.mean(runtime_list)
    std_runtime = np.std(runtime_list)
    return avg_runtime, std_runtime


### Hyperparameter Optimization Algorithm ###
def your_algorithm(dataset, batch_size, iterations=1):
    num_workers_list = [0, 2, 4, 8, 16, 32, 64, 128, 256, 512]
    prefetch_factor_list = [2, 4, 8, 16,32 ,64]
    persistent_workers_list = [False, True]
    pin_memory_list = [False, True]

    best_config = None
    best_runtime = float('inf')
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    for num_workers in num_workers_list:
        for prefetch_factor in ([None] if num_workers == 0 else prefetch_factor_list):
            for persistent_workers in ([False] if num_workers == 0 else persistent_workers_list):
                for pin_memory in pin_memory_list:
                    # Skip invalid configurations
                    if num_workers == 0 and persistent_workers:
                        continue

                    dataloader = DataLoader(
                        dataset=dataset,
                        batch_size=batch_size,
                        num_workers=num_workers,
                        prefetch_factor=prefetch_factor,
                        persistent_workers=persistent_workers,
                        pin_memory=pin_memory,
                    )
                    
                    avg_runtime, _ = measure_time(dataloader, device)

                    # Update the best configuration
                    if avg_runtime < best_runtime:
                        best_runtime = avg_runtime
                        best_config = {
                            'num_workers': num_workers,
                            'prefetch_factor': prefetch_factor,
                            'persistent_workers': persistent_workers,
                            'pin_memory': pin_memory,
                        }
                        

    print("Best Configuration:", best_config)
    print(f"Best Runtime: {best_runtime:.4f} ms")
    return best_config


### Main Execution ###
if __name__ == "__main__":
    batch_size = 2 #  32, ,64 ,128 ,256 
    dataset = MiniImageNetDataset(
        root_dir='/home/myhoon/work/dataloader/dataloader', #주소 변경 필수 
        split='train',
        transform=transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.RandomCrop((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]),
        ])
    )

    # Hyperparameter search
    a_start_time = time.time()
    best_config = your_algorithm(dataset, batch_size, iterations=1)
    a_end_time = time.time()

    # Create DataLoader with the best configuration
    dataloader = DataLoader(dataset=dataset, batch_size=batch_size, **best_config)

    # Measure final runtime
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    avg_runtime, std_runtime = measure_time(dataloader, device)

    print("\n--- Final Results ---")
    print(f"Best Configuration: {best_config}")
    print(f"Average Runtime: {avg_runtime:.4f} ms")
    print(f"Standard Deviation: {std_runtime:.4f} ms")
    print(f"Parameter Search Time: {a_end_time - a_start_time:.4f} seconds")
