import os
import time
import warnings
import numpy as np
from PIL import Image

import torch
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms

import argparse

warnings.filterwarnings("ignore")


### Dataset ###
class MiniImageNetDataset(Dataset):
    def __init__(self, root_dir, split='train', transform=None):
        """
        Args:
            root_dir (string): Root directory of the dataset.
            split (string): 'train', 'val', or 'test' split.
            transform (callable, optional): Optional transform to be applied on a sample.
        """
        self.root_dir = root_dir
        self.split = split
        self.transform = transform

        self.image_paths = []
        self.labels = []

        # Load image paths and labels
        split_path = os.path.join(root_dir, f'{split}.csv')
        with open(split_path, 'r') as f:
            next(f)
            for line in f:
                img_name, label = line.strip().split(',')
                self.image_paths.append(os.path.join(root_dir, 'images', img_name))
                self.labels.append(label)
        self.label2idx = {label: idx for idx, label in enumerate(sorted(set(self.labels)))}

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image = Image.open(self.image_paths[idx]).convert('RGB')
        label = self.labels[idx]
        label = self.label2idx[label]

        if self.transform:
            image = self.transform(image)

        return image, label


### DataLoader measure time ###
def measure_time(dataloader, device):
    runtime_list = []
    for i, t in dataloader:
        stime = time.perf_counter_ns()
        i, t = i.to(device), t.to(device)
        if device.type == 'cuda':
            torch.cuda.synchronize()  # Wait for GPU tasks to finish
        etime = time.perf_counter_ns()
        runtime_list.append((etime - stime) * 1e-6)  # Convert ns to ms

    if len(runtime_list) == 0:
        return float('inf'), 0  # Default for no data
    avg_runtime = np.mean(runtime_list)
    std_runtime = np.std(runtime_list)
    return avg_runtime, std_runtime


### config ###
def your_algorithm(dataset, batch_size):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    # num_workers_list = int(os.count()/2)
    # prefetch_factor_list = [2]
    # persistent_workers=[False]
    # pin_memory_list=[False]
    default_config = {
        'num_workers': int(os.cpu_count()/2),
        'prefetch_factor': 2,
        'persistent_workers': False,
        'pin_memory': False,
        }
    dataloader = DataLoader(dataset, batch_size=32, **default_config)
    avg_runtime, _ = measure_time(dataloader, device)
    print("Best Configuration:", default_config)
    print(f"Best Runtime: {avg_runtime:.4f} ms")
    return default_config





if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--batch_size",type=int, default =2, help = "Batch size for DataLoader") # 32, ,64 ,128 ,256 
    args = parser.parse_args()
    batch_size = args.batch_size
    dataset = MiniImageNetDataset(
        root_dir='/home/myhoon/work/dataloader/dataloader',
        split='train',
        transform=transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize((256, 256)),
            transforms.RandomCrop((224, 224)),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            ),
        ])
    )

    # 
    a_start_time = time.time()
    default_config = your_algorithm(dataset,batch_size) # Measure the time of parameter searching
    a_end_time = time.time()

    # DataLoader creation
    dataloader = DataLoader(dataset, batch_size, **default_config)

    # Measure the time of dataloading 
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    avg_runtime, std_runtime = measure_time(dataloader, device)

    # Result
    print("Default Configuration:", default_config)
    print(f"Average Runtime: {avg_runtime:.4f} ms")
    print(f"Standard Deviation: {std_runtime:.4f} ms")
    print(f"Parameter Search Time: {a_end_time - a_start_time:.4f} seconds")


