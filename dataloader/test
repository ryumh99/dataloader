import subprocess
import re
import numpy as np
import csv
import os

import argparse

from collections import Counter

scripts = ["dataloader_grid_gpu", "dataloader_grid_cpu"]
headers = ["Scripts", "Run", "Average_runtime", "Standard_Deviation", "Parameter_Search_time", "Best_Configuration"]

def save_results_to_csv(file_path, results):
    with open(file_path, mode="w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(headers)
        writer.writerows(results)

def extract_values(output):
    avg_runtime_match = re.search(r"Average Runtime:\s*([\d.]+)", output)
    std_runtime_match = re.search(r"Standard Deviation:\s*([\d.]+)", output)
    param_search_time_match = re.search(r"Parameter Search Time:\s*([\d.]+)", output)
    best_config_match = re.search(r"Best Configuration:\s*({.*})", output)

    avg_runtime = float(avg_runtime_match.group(1)) if avg_runtime_match else None
    std_runtime = float(std_runtime_match.group(1)) if std_runtime_match else None
    param_search_time = float(param_search_time_match.group(1)) if param_search_time_match else None
    best_config = eval(best_config_match.group(1)) if best_config_match else None

    return avg_runtime, std_runtime, param_search_time, best_config

def run_and_average(script_path, batch_size, runs=10):
    avg_runtimes = []
    std_runtimes = []
    param_search_times = []
    best_configs = []
    individual_results = []

    for run in range(1, runs + 1):
        try:
            result = subprocess.run([
                "python", script_path, "--batch_size", str(batch_size)
            ], capture_output=True, text=True, check=True)
            avg_runtime, std_runtime, param_search_time, best_config = extract_values(result.stdout)

            if avg_runtime is not None:
                avg_runtimes.append(avg_runtime)
            if std_runtime is not None:
                std_runtimes.append(std_runtime)
            if param_search_time is not None:
                param_search_times.append(param_search_time)
            if best_config is not None:
                best_configs.append(str(best_config))

            individual_results.append([
                script_path, run, avg_runtime, std_runtime, param_search_time, str(best_config)
            ])
        except subprocess.CalledProcessError as e:
            individual_results.append([script_path, run, None, None, None, "Error: " + e.stderr.strip()])
        except Exception as e:
            individual_results.append([script_path, run, None, None, None, "Error: " + str(e)])

    avg_runtime_mean = np.mean(avg_runtimes) if avg_runtimes else None
    std_runtime_mean = np.mean(std_runtimes) if std_runtimes else None
    param_search_time_mean = np.mean(param_search_times) if param_search_times else None

    best_config_counter = Counter(best_configs)
    most_common_config = eval(best_config_counter.most_common(1)[0][0]) if best_configs else None

    summary_result = [
        script_path, "Average", avg_runtime_mean, std_runtime_mean, param_search_time_mean, most_common_config
    ]

    return individual_results, summary_result

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--batch_size", type=int, default = 8, required=True, help="Batch size for the scripts")
    args = parser.parse_args()

    batch_size = args.batch_size
    output_csv = f"grid_search_{batch_size}_results.csv"

    all_results = []
    summary_results = []

    for script in scripts:
        if not os.path.exists(script):
            all_results.append([script, "Error", None, None, None, "File not found"])
            continue

        individual_results, summary_result = run_and_average(script, batch_size, runs=10)
        all_results.extend(individual_results)
        summary_results.append(summary_result)

    # CSV 파일에 결과 저장
    save_results_to_csv(output_csv, all_results + summary_results)

    print(f"Results saved to {output_csv}")
